dataset_params:
  im_path : 'dataset/data'
  im_size : 32
  im_channels : 3
  mean : [0.485, 0.456, 0.406]
  std  : [0.229, 0.224, 0.225]
  interpolation_mode : BICUBIC

  # Color jitter params
  cj_brightness : 0.4
  cj_contrast : 0.4
  cj_saturation : 0.4
  cj_hue : 0.1
 
tsd_params:
  emb_dim : 128
  num_encoder_layers_tiny : 2
  num_encoder_layers_big : 6
  num_heads_tiny : 2
  num_heads_big : 4
  cte_output_channels : 64
  expansion_ratio : 4
  
train_params:
  seed : 1111
  task_name: 'classification_only'
  train_batch_size : 32
  val_batch_size : 16
  warm_up_epochs : 5
  train_epochs: 25
  begin_train_epoch : 0
  optimizer_name : "AdamW"
  train_lr : 0.0001
  train_wd : 0.01 # weight decay factor to be used in Adam and AdamW 
  TRAIN_WITHOUT_WD : ['dw', 'bn', 'ln', 'bias'] # List of Layer names whose weight should not be decayed in AdamW 
  pin_memory : True
  num_workers : 2
  amp_enabled :  False
  clip_grad_norm : 1.0
  compile_model : True

  # Config for checkpointing
  tsd_ckpt_name: 'tsd_ckpt.pth'
  AUTO_RESUME : True
  TRAIN_CHECKPOINT : ''
  checkpoint_dir : 'checkpoints'
  
  # Config for ReduceLROnPlateau
  lr_scheduler_name : "ReduceLROnPlateau"
  patience_epochs : 5
  reduce_lr_factor : 0.1
  loss_reduction_threshold : 1e-4
  
  # Config for CosineAnnealing Scheduler
  eta_min : 1e-5
  